{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_x/8clrdsj55jv7dc605rcxqx3r0000gn/T/ipykernel_1991/2922089001.py:169: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(\n",
      "/var/folders/_x/8clrdsj55jv7dc605rcxqx3r0000gn/T/ipykernel_1991/2922089001.py:175: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "/var/folders/_x/8clrdsj55jv7dc605rcxqx3r0000gn/T/ipykernel_1991/2922089001.py:178: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = ZeroShotAgent(\n",
      "/var/folders/_x/8clrdsj55jv7dc605rcxqx3r0000gn/T/ipykernel_1991/2922089001.py:198: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"deepseek-llm:7b-chat\")\n",
      "/var/folders/_x/8clrdsj55jv7dc605rcxqx3r0000gn/T/ipykernel_1991/2922089001.py:219: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = agent_executor({\"input\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe role of counselling in preventing drug addiction is to provide guidance, support and education on healthy decision-making and coping strategies. Counselling can help individuals identify potential triggers for drug use, develop problem-solving skills, manage emotions and stress effectively, and build resilience against the pressures that may lead them to abuse drugs.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "  \"input\": \"What is the role of counselling in preventing drug addiction?\",\n",
      "  \"output\": \"Agent stopped due to iteration limit or time limit.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.agents import Tool, AgentExecutor, ZeroShotAgent\n",
    "from langchain.llms import Ollama\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def pdf_retriever_function(query):\n",
    "    \"\"\"Function to retrieve information from PDF\"\"\"\n",
    "    return f\"Retrieved information for query: {query}\"\n",
    "\n",
    "# Define tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"PDF_Search\",\n",
    "        func=pdf_retriever_function,\n",
    "        description=\"Search through the PDF document\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Updated prompt template to enforce strict JSON formatting\n",
    "template = \"\"\"Answer the following question as best you can.\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "IMPORTANT: Your response must be a valid JSON object with exactly this format:\n",
    "{{\n",
    "    \"answer\": \"your concise answer here\",\n",
    "    \"explanation\": \"your detailed explanation here\"\n",
    "}}\n",
    "\n",
    "Do not include any text outside of this JSON structure. Make sure to escape any quotes within your answer and explanation.\n",
    "\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"input\", \"agent_scratchpad\"]\n",
    ")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = Ollama(model=\"deepseek-llm:7b-chat\")\n",
    "\n",
    "# Create the chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Create the agent with handle_parsing_errors enabled\n",
    "agent = ZeroShotAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Create the agent executor with parsing error handling\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True  # Add this to handle parsing errors\n",
    ")\n",
    "\n",
    "def load_pdf_and_create_vector_store(pdf_path):\n",
    "    \"\"\"Load PDF and create vector store\"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "    embeddings = OllamaEmbeddings(model=\"deepseek-llm:7b-chat\")\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def query_agent(question: str):\n",
    "    \"\"\"Query the agent with a question\"\"\"\n",
    "    try:\n",
    "        # Execute the query\n",
    "        response = agent_executor({\"input\": question})\n",
    "        \n",
    "        # If the response is a string (raw LLM output), try to format it as JSON\n",
    "        if isinstance(response, str):\n",
    "            try:\n",
    "                # Try to extract just the JSON part if there's extra text\n",
    "                json_start = response.find('{')\n",
    "                json_end = response.rfind('}') + 1\n",
    "                if json_start >= 0 and json_end > 0:\n",
    "                    json_str = response[json_start:json_end]\n",
    "                    return json.loads(json_str)\n",
    "                else:\n",
    "                    # If no JSON found, format the entire response\n",
    "                    return {\n",
    "                        \"answer\": response[:500],  # Truncate long answers\n",
    "                        \"explanation\": \"Response was formatted as plain text\"\n",
    "                    }\n",
    "            except json.JSONDecodeError:\n",
    "                # If JSON parsing fails, return the response in our format\n",
    "                return {\n",
    "                    \"answer\": response[:500],  # Truncate long answers\n",
    "                    \"explanation\": \"Full response in explanation\"\n",
    "                }\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return {\n",
    "            \"answer\": \"Error occurred while processing the query\",\n",
    "            \"explanation\": str(e)\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize vector store\n",
    "    pdf_path = \"English.pdf\"\n",
    "    vectorstore = load_pdf_and_create_vector_store(pdf_path)\n",
    "    \n",
    "    # Test the system\n",
    "    query = \"What is the role of counselling in preventing drug addiction?\"\n",
    "    result = query_agent(query)\n",
    "    print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
